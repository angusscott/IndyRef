
% to choose your degree
% please un-comment just one of the following
\documentclass[bsc,frontabs,singlespacing,parskip]{infthesis}     % for BSc, BEng etc.
%Readd twoside to make it stick to a side 


% \documentclass[minf,frontabs,twoside,singlespacing,parskip]{infthesis}  % for MInf
\usepackage{todonotes}
\usepackage{cite}
\begin{document}

\title{Inferring Political Opinion From Social Media Data }

\author{Angus Scott}

% to choose your course
% please un-comment just one of the following
\course{Artificial Intelligence and Computer Science}
%\course{Artificial Intelligence and Software Engineering}
%\course{Artificial Intelligence and Mathematics}
%\course{Artificial Intelligence and Psychology }   
%\course{Artificial Intelligence with Psychology }   
%\course{Linguistics and Artificial Intelligence}    
%\course{Computer Science}
%\course{Software Engineering}
%\course{Computer Science and Electronics}    
%\course{Electronics and Software Engineering}    
%\course{Computer Science and Management Science}    
%\course{Computer Science and Mathematics}
%\course{Computer Science and Physics}  
%\course{Computer Science and Statistics}    

% to choose your report type
% please un-comment just one of the following
%\project{Undergraduate Dissertation} % CS&E, E&SE, AI&L
%\project{Undergraduate Thesis} % AI%Psy
\project{4th Year Project Report}

\date{\today}

\abstract{
This is an example of {\tt infthesis} style.
The file {\tt skeleton.tex} generates this document and can be 
used to get a ``skeleton'' for your thesis.
The abstract should summarise your report and fit in the space on the 
first page.
%
You may, of course, use any other software to write your report,
as long as you follow the same style. That means: producing a title
page as given here, and including a table of contents and bibliography.
}

\maketitle

\section*{Acknowledgements}
Insert Acknowledgements here.
\tableofcontents

%\pagenumbering{arabic}


\chapter{Introduction}
\todo{introduce what latent attributes are}

\todo{Include detail on why IndyRef is different from american and german elections}




\chapter{Related Work}

The inference of user attributes from different sources of media has been well considered both in the context of traditional media and new media.\todo{include links to papers that have perofrmed tasks in different media} 



A natural extension to this task has been to apply similar methods to the microblogging service Twitter. Previous work includes detection of \textit{gender}, \textit{ethinicity}, \textit{brand loyalty}, \textit{regional origin} and \textit{age}.\cite{yahoopaper}\cite{rao2010}

The detection of \textit{Political Affiliation} has also been considered. Most of the research in this area has been focused on one of two political systems. First is the American system, with the 2010 Congressional Midterms\cite{Conover2010predicting}  \cite{politicalpolar}\cite{yahoopaper} or the 2012 Presidential Elections \cite{quantpol}. Second is the German system, with the 2009 federal election to the national parliament\cite{predelections}\cite{dividedtheytweet}. 

Approaches to the task of inference of latent attributes from twitter can be broadly split into two categories:
\begin{enumerate}
\item{Use of the networked structure of the data}
\item{Analysis of user communication streams}
\end{enumerate}

\section{Network Structure}

It has long been known that individuals form information networks corresponding to their own political preferences \cite{socialflow}, and this has continued into online social networks \cite{birdsofafeather}. This demonstrates that people who participate in particular networks, are likely to share similar political values or opinions, which could be used to infer someones political beliefs.

There are four main types of networks that have previously been exploited to infer political persuasion:
\begin{itemize}
\item{\textit{Follower} - }
\item{\textit{Mention} - }
\item{\textit{Retweet} - }
\item{\textit{Hyperlink} - }
\end{itemize}

\section{User Communication}

Sentiment Analysis 
Topic Modelling
Support Vector Machines
Decision Trees

\chapter{Related Work}

Broadly split into three approaches:

\section{Profile features and Tweeting behaviour: ``Who you are and how you tweet"}

\section{Lexical content: ``What you tweet"}
\label{sec:lingcont}

Tweets contain lexical information which directly conveys the thoughts and opinions of users. By analysing what the user says/discusses, we can observe similarities between users and from this, group users into different classes. It would be reasonable to assume that users of social media are likely to discuss topics that are of importance/interest to them, and people who share political ideologies/opinions would be likely to discuss similar topics. 

Conover et al.(2010) \cite{Conover2010predicting} propose the use of linear support vector machines (SVMs) to classify 1,000 `highly connected' users into `left' and `right' political classes. The users were manually annotated into `left', `right' and `ambiguous' classes. The tweets were collected over the six weeks preceding the 2010 U.S Midterm Elections. The authors compute accuracy for SVMs built with:
\begin{description}
\item[Full-text] TF-IDF weighted unigrams of tweets (hashtags, mentions, URLs and stop words removed)
\item[Hashtags] Bag of words representation of hashtags in tweets (removed all text that wasn't hashtags and hashtags only used by one user)
\item[Latent Semantic Analysis of Hashtags (LSA)] Applied to the hashtag-user matrix to identify latent factors that correspond to political alignment. 
\end{description}

It was found that the SVM trained on the full-text corpus obtained an accuracy of 79.2\%, but when trained on hashtags the classifier obtained 90.8\%. The addition of LSA to hashtags with the first three dimensions had a minimal improvement on accuracy of 0.1\%, and the addition of subsequent features only decreased performance. 

The paper also makes use of the social network, and is discussed in section \ref{sec:socnet} along with further discussion of what it means to be a `highly connected' user and why the results in this paper may be overly optimistic.

Tumasjan et al. \cite{predelections} is one of the most highly cited of the papers discussed here, and establishes the use of sentiment analysis as a means of detecting political persuasion. The paper uses a corpus of 100,000 tweets referencing the German federal election, collected over the 5 weeks preceding the election. The authors use the LIWC text analysis software and focus on 12 dimensions they feel are relevant to political sentiment: Future orientation, past orientation, positive emotions, negative emotions, sadness, anxiety, anger, tentativeness, certainty, work, achievement, and money.

The paper establishes that the tweets in their corpus were dominated by a small number of users, implying that a  small number of users control the majority of the opinion on Twitter. The authors also establish that candidates who are further from the centre politically have more exaggerated sentiment scores amongst the 12 dimensions mentioned above. The paper concludes by attempting to show that the number of tweets about particular parties reflect the election outcome, and that co-occurrences of two parties reflect real life coalition partners. 

Despite the paper being highly cited, there are two primary criticisms of this paper. First is that tweets were translated from German to English using some machine translation system, and sentiment scores were then calculated from the English translations, even though the LIWC software has a German dictionary. This is likely to introduces a considerable amount of noise, particularly in tweets where slang and incorrect/non-standard grammar is used. Balamurali et al. \cite{balamurali2013lost} found that sentiment analysis performed on translated text performed poorly compared to native text, they attributed this to the failure of the translation system to capture cultural divergence between languages with respect to expressions of sentiment.

The second criticism is the conclusion that number of tweets reasonably reflects the outcome of the election. The authors only compare against one election, and one data point is clearly not enough for any meaningful evaluation. In fact, in the Scottish Referendum corpus, constructed as part of this project, the number of `Yes' leaning tweets exceeds the number of `No' leaning tweets significantly, even though the No Campaign ended up being victorious. 

Pennacchiotti and Popescu \cite{yahoopaper} make use of gradient boosted decision trees (GBDT), combining a collection of weak leaners to form a strong learner. The authors built a balanced corpus of 10,338 self identifying Democrat and Republican voters, with political leanings scrapped from various sources. 

Their weak leaners are a combination of linguistic features and network features, which will be discussed in section \ref{sec:socnet}. The authors use the following linguistic features:

\begin{description}
\item[Prototypical Words] Collection of the 200 most class indicative words per class. Scored by measuring the ratio between the number of occurrences in a class and the number of occurrences in all classes. Similar to Full-Text above, but with less noise.
\item[Prototypical Hashtags] Collection of the 100 most class indicative hashtags per class. Scored by measuring the ratio between the number of occurrences in a class  and the number of occurrences in all classes. Similar to Hashtags above, but with less noise.
\item[Generic Latent Dirichlet Analysis (GLDA)] 100 course grained topics built from corpus of 4 million users. The model is then applied to each test user in order to obtain their topic distribution, which are the features used for classification.
\item[Domain Specific Latent Dirichlet Analysis (DLDA)] Similar to the above, but model is built on users in training set. This produces more fine grained topics that are more class discriminative. 
\item[Sentiment Words] Authors created a small collection of terms $t$ that divide opinions between Republicans and Democrats, and used the tool Opinion Finder 1.5 to find cases where a word carrying sentiment was used with respect to a term in $t$. This was used across all the users tweets, and their scores tallied, to produce a score which indicates your most likely class. 
\end{description}

The authors created a decision tree for each of the features above, and created an All function which is a GBDT, an ensemble of the above features. Prototypical Words have an accuracy of 73\%, Prototypical Hashtags 70\%, GLDA 67\%, DLDA 76\%, Sentiment Words 70\% and All with 77\%. 

The above paper describes a range of linguistic methods, all of which are reasonable individually, but combine to become a fairly good classifier. When you introduce social network features - discussed in section \ref{sec:socnet} - the model performs strongly with an accuracy of 89\%. 

\section{Social network: ``Who you tweet"}
\label{sec:socnet}


Introduce why networks work, i.e. homophilic properties

Conover et al. (2011) \cite{politicalpolarisation} investigates the structure of retweet and user-to-user mention networks. The authors built a corpus of 250,000 tweets over the six weeks leading up to the 2010 U.S congressional midterms. With users given a class label `Republican' or `Democrat'. The authors used a combination of network clustering algorithms, statistical analysis of political tweet content and manually-annotated data. 

Using these tools, the authors found that retweet networks are highly polarised, taking the form of two large clusters of users who distribute content to others in their cluster, with very little overlap between the two clusters. Conversely, it was found that no such structure existed in the user-to-user mention networks, and instead was formed as one large politically heterogenous cluster, where ideologically opposed users interact at a much high rate than in the retweet network. 

The partisan nature of the discourse in retweet networks makes it ideal for the use of classification, hence many of the studies in this area have focused on the use of retweet networks for the purpose of classification.


In addition to their use of linguistic features, Conover et al. (2010) \cite{Conover2010predicting} make use of the social network to classify users. They argue that as many social networks exhibit homophilic properties as described above, they can be used to infer properties about users who tend to associate with one another. The authors form a retweet network composed of the 1,000 most connected users, in other words the 1,000 node subgraph, such that the sum total of the node's connections to the other nodes of the 1,000 node subgraph is maximised.

To classify users the authors used a greedy label propagation method. Each of the 1,000 nodes was given a class 1 or class 2  label using Newman's eigenvector modularity maximisation technique. The algorithm then begins iteratively assigning each node to the class shared by the majority of it's neighbours, and randomly assigning when a tie occurs. This was done until the algorithm converged on a solution. 

The authors found a strong associated between cluster membership and political alignment, and suggested a simple classifier of `Left' if in class 1 or `Right' if in class 2. The method had an accuracy of 95\%, higher than using semantic information. The authors also attempted to combine the two methods by combining cluster assignments and 19 hashtag features selected using Hall's feature selection algorithm and an SVM, but found it performed no better than network clustering alone. 

Whilst the paper provides a solid approach to tackling the problem of detecting political alignment, there is a concern over a biased selection of users for training and testing. By selecting the 1,000 most highly connected users, it is likely that the results are biased, because as Tumasjan et al. \cite{predelections} note, a small number of users dominate the communication in Twitter, and it is very likely that these highly connected users are part of that small group as retweets represent connections, which are observed through communication. Therefore the users who are used for training/evaluation, have an unusually high amount of linguistic content, and connections when compared to most other Twitter users. This leads to the possibility that the results are overly optimistic, if the aim is to use this as a means of classification for general twitter users. 

Pennacchiotti and Popescu \cite{yahoopaper} make use of gradient boosted decision trees (GBDT), combining a collection of weak leaners to form a strong learner. The authors make use of linguistic features (discussed in section \ref{sec:lingcont}) and the following network features:

\begin{description}
\item[Follower Network] Collection of the most exemplar users per class. Scored by measuring the ratio between the number of occurrences in a class and the number of occurrences in all classes. Then for each exemplar user in the collection, a boolean feature is set to `1' if a user follows them, and `0' otherwise.

\item[Mention Network] 
\item[Retweet Network]
\end{description}

\chapter{Data and Methodolgy}
\section{Scotland Independence Referendum Background}
\label{sec:indybackground}
The Scottish Referendum on Independence was a referendum on Scottish Independence with the intention of establishing Scotland as an independent sovereign state, independent of the rest of the United Kingdom. The election took place on the 18th September 2014, with record turnout of 84.59\% and an electorate of 4,283,392. The referendum concluded with a ``No'' side victory of 55.3\%, over the ``Yes'' side with 44.7\%.

Yes Scotland was the primary campaigning group behind independence, whilst Better Together were campaigning to maintain the union with the rest of the United Kingdom. Many other campaigning groups, including: political parties, businesses, newspapers and famous individuals, were also involved in the campaign. The campaign was widely discussed on social media, with estimates by YouGov stating that 54\% of the electorate got information, regarding the campaign, from social media and other websites. There was much debate during the campaign, on issues including: currencies and monetary policy, public expenditure, EU membership and north sea oil revenues. 

There was also considered to be several key events on the run-up to the campaign, including The Commonwealth Games that were hosted in Glasgow Glasgow

\section{The Twitter Platform}
\label{sec:twitterplatform}
Twitter is a popular microblogging and social network site that allows users to send and read short 140 character messages commonly known as \textit{tweets}. Tweets as used in this report include the 140 character message, along with the associated metadata. This includes features such as: creation dates, user follower counts, coordinates and language. 

As well as tweeting\footnote{Tweeting - The act of broadcasting a tweet} to an audience of \textit{followers}, Twitter users can interact publicly through two main approaches: \textit{retweets} and \textit{mentions}. Retweets often indicate agreement\cite{retweetagreement}, allowing users to rebroadcast content from other users, having the effect of spreading tweets to a larger audience\cite{largeraudiance}. Alternatively, mentions work by allowing someone to refer to a particular Twitter user by including their \texttt{@username} in a tweet, creating a public dialogue between the referrer and referee.

\textit{Hashtags} are another important feature of Twitter, allowing users to tag tweets according to topic and their intended audience. For example \texttt{\#IndyRef} was often used to reference the topic of the Independence Referendum, or \texttt{\#bettertogether} which generally indicated that someone was No Voter or was addressing No Voters.

Twitter has several benefits over other social networking sites \cite{benefitsoftwitter}\cite{quantpol} including:
\begin{enumerate}
\item{Twitter users retweet notable events and participate in the spread of realtime news.}
\item{The 140 character constraint forces tweets to be concise and to the point.}
\item{Users are highly reactionary and discussed events tend to have happened in the recent past.}
\item{Tweets are media rich, and include content like video, image and hyperlinks along with text.} 
\end{enumerate}

\section{Dataset}

The dataset was collected following the referendum, and is composed of X tweets from Y users, spanning from the 1st February 2014, to 17th September 2014, \todo{Add number of users here} the day prior to the Independence Referendum. The corpus also includes set of user classifications obtained through annotation of  users tweets from the 18th of September.

The first steps in building the corpus, was to obtain tweets from the 18th of September 2014. This first set of tweets were obtained from a Twitter Mining system developed by Sasa Petrovic and Miles Osborne as part of their efforts to create the Edinburgh Twitter Corpus. From this I  was given a collection of tweets that matched a set of hashtags commonly used by users involved in the Yes and No campaigns. 

Hashtags, and their associated campaign are given in Table \ref{tab:hashtagtable}, which were obtained using the hashtagify.me tool. It is worth noting that this is a set of non-event specific hashtags. Whilst hashtags such as \texttt{\#PatronisingBTlady}\cite{patronisingbtlady} are politically divisive, they have been excluded as they have a short lifespan as discussed in Section \ref{sec:twitterplatform}, and are therefore unlikely to be used on the final day of the referendum. 

\begin{table}
\begin{center}
    \begin{tabular}{ c p{7cm} }
    \hline
    Topic Indicators: & \tt{\#indyref, \#scotland, \#scotdecides, \#scotlanddecides, \#independence} \\ \hline	
     Yes Campaign: & \tt{\#voteyes, \#yesscotland, \#yesscot, \#youyesyet}\\ \hline
     No Campaign: & \tt{\#voteno, \#nothanks, \#bettertogether, \#letsstaytogether} \\ \hline
    Political Parties/Politicians: & \texttt{\#snp, \#labour, \#conservative, \#tory, \#libdem, \#salmond, \#alexsalmond,\#davidcameron, \#gordonbrown, \#alistairdarling}\\
	\hline
   \end{tabular}
\caption{Set of hashtags related to the campaign}
  \label{tab:hashtagtable}
\end{center}
\end{table}
\todo{Include graph showing strength of hashtag, and how many tweets it appears in }
These tweets are then used as evidence for the annotators to classify a user as Y (Voted Yes in the referendum), N (Voted No in the referendum) or U (Unknown or Undeterminable). We make the assumption that tweets on the final day are the most emblematic of how a user voted, as the opportunity to flip their opinion is minimised andTwitter activity surrounding the event was at it's peak. This is done as there are both technical and ethical issues about obtaining classifications more directly.

After providing a class for each user, we then collect all their publicly available tweets, available from 1st February to 17th September, and their associated meta data using the Twitter API \footnote{Due to a limitation of the Twitter API, you can only collect from the last 3200 published tweets.}. 

\section{General approach to user profiling}
\todo{Detail what can be measured in Twitter and how we could use it}
\section{Models}
\todo{Models I plan on implementing, may be moved to eval section}
\subsection{Naive Bayes}
\subsection{Topic Modelling}
\subsection{SVM}
\subsubsection{One class SVMs}
\subsubsection{Alternative SVMs, standard?}
\subsection{Gradient Boosted Decision Trees}
\chapter{Evaluation}
\chapter{Conclusions and Further Work}


% use the following and \cite{} as above if you use BibTeX
% otherwise generate bibtem entries
\bibliography{bibliography}
\bibliographystyle{plain}


\end{document}
